{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://iict-space.heig-vd.ch/apu/wp-content/uploads/sites/21/2022/01/2020-slim.png\" alt=\"HEIG-VD Logo\" width=\"100\" align=\"right\"/>\n",
    "\n",
    "# Cours TAL - Laboratoire 3 : Analyse syntaxique du français\n",
    "\n",
    "**Objectifs**\n",
    "\n",
    "1. Utiliser un analyseur syntaxique **en constituants** pour extraire tous les groupes nominaux d'un texte.\n",
    "1. Appliquer un analyseur syntaxique **de dépendances** sur des données de test en français et calculer son score.\n",
    "1. Entraîner l'analyseur **de dépendances** sur des données adaptées et mesurer si les performances se sont améliorées ou non."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.\tUtiliser un analyseur syntaxique en constituants pour extraire les groupe nominaux\n",
    "\n",
    "Vous utiliserez l'analyseur syntaxique en constituants appelé `LexicalizedParser` fourni parmi les outils CoreNLP de Stanford, et [documenté ici](https://nlp.stanford.edu/nlp/javadoc/javanlp/edu/stanford/nlp/parser/lexparser/LexicalizedParser.html).  \n",
    "\n",
    "\n",
    "* **code Java** : fichier `stanford-corenlp-3.9.2.jar` (8 Mo) fourni sur Cyberlearn\n",
    "* **modèle** : fichier `frenchFactored.ser.gz` (4 Mo) fourni sur Cyberlearn\n",
    "* **données** : fichier `exemple.txt` fourni sur Cyberlearn\n",
    "\n",
    "a. Veuillez écrire la ligne de commande (java) qui effecte l'analyse syntaxique en constituants du texte `exemple.txt`. Choisissez 'oneline' comme format et écrivez les résultats dans un ficher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading parser from serialized file frenchFactored.ser.gz ... done [1.3 sec].\n",
      "Parsing file: exemple.txt\n",
      "edu.stanford.nlp.international.french.process.FrenchLexer: Invalid options key in constructor: splitContractions\n",
      "Parsing [sent. 1 len. 12]: Les gares voyageurs sont en fait des ensembles fonctionnels plus larges .\n",
      "Parsing [sent. 2 len. 20]: Elles regroupent toutes les fonctions centrées sur l' accès à le train et l' achat des titres de transport .\n",
      "Parsing [sent. 3 len. 11]: Elles offrent aussi divers services commerciaux liés à le voyage .\n",
      "Parsing [sent. 4 len. 16]: Pour certaines gares , le passage de nombreux voyageurs justifie l' installation de fonctions annexes .\n",
      "Parsing [sent. 5 len. 13]: Il s' agit , par exemple , de commerces et services variés .\n",
      "Parsing [sent. 6 len. 12]: Les gares peu importantes sont appelées haltes ou points d' arrêt .\n",
      "Parsing [sent. 7 len. 23]: Le train est un matériel roulant ferroviaire assurant le transport de personnes ou de marchandises sur une ligne de chemin de fer .\n",
      "\n",
      "*******************************************************\n",
      "***  WARNING!! OUT OF MEMORY! THERE WAS NOT ENOUGH  ***\n",
      "***  MEMORY TO RUN ALL PARSERS.  EITHER GIVE THE    ***\n",
      "***  JVM MORE MEMORY, SET THE MAXIMUM SENTENCE      ***\n",
      "***  LENGTH WITH -maxLength, OR PERHAPS YOU ARE     ***\n",
      "***  HAPPY TO HAVE THE PARSER FALL BACK TO USING    ***\n",
      "***  A SIMPLER PARSER FOR VERY LONG SENTENCES.      ***\n",
      "*******************************************************\n",
      "\n",
      "Sentence too long for dependency parser.  Falling back to PCFG parse...\n",
      "Parsing [sent. 8 len. 19]: Par extension , on appelle train le service que constitue chacun de ces transports , réguliers ou non .\n",
      "Parsing [sent. 9 len. 14]: Le train est un mode de transport , s' effectuant sur voie ferrée .\n",
      "Parsing [sent. 10 len. 40]: Cependant , dans l' usage courant , le mot train désigne n' importe quelle circulation ferroviaire , quelle que soit sa composition , depuis le plus simple autorail local jusqu'aux longs trains de grandes lignes ou de transports industriels .\n",
      "Sentence too long for dependency parser.  Falling back to PCFG parse...\n",
      "Parsed file: exemple.txt [10 sentences].\n",
      "\n",
      "*******************************************************\n",
      "***  WARNING!! OUT OF MEMORY! THERE WAS NOT ENOUGH  ***\n",
      "***  MEMORY TO RUN ALL PARSERS.  EITHER GIVE THE    ***\n",
      "***  JVM MORE MEMORY, SET THE MAXIMUM SENTENCE      ***\n",
      "***  LENGTH WITH -maxLength, OR PERHAPS YOU ARE     ***\n",
      "***  HAPPY TO HAVE THE PARSER FALL BACK TO USING    ***\n",
      "***  A SIMPLER PARSER FOR VERY LONG SENTENCES.      ***\n",
      "*******************************************************\n",
      "\n",
      "Parsed 180 words in 10 sentences (44,90 wds/sec; 2,49 sents/sec).\n",
      "  2 sentences were parsed by fallback to PCFG.\n"
     ]
    }
   ],
   "source": [
    "! java -Xmx1024m -cp stanford-corenlp-3.9.2.jar edu.stanford.nlp.parser.lexparser.LexicalizedParser -outputFormat oneline -writeOutputFiles frenchFactored.ser.gz exemple.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Importez le fichier de résultats du LexicalizedParser comme une liste d'arbres, en utilisant la classe `BracketParseCorpusReader` de NLTK.  Chaque ligne contenant une analyse syntaxique sera importée comme un objet `Tree` de NLTK. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus.reader.bracket_parse import BracketParseCorpusReader\n",
    "from nltk.tree import Tree\n",
    "from nltk.draw.tree import TreeView\n",
    "\n",
    "bracket = BracketParseCorpusReader('.', 'exemple.txt.stp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'BracketParseCorpusReader' object has no attribute 'detect_blocks'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-da99bbd9172b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbracket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetect_blocks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'BracketParseCorpusReader' object has no attribute 'detect_blocks'"
     ]
    }
   ],
   "source": [
    "bracket.detect_blocks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. Cherchez dans la [documentation](https://www.nltk.org/_modules/nltk/tree.html#Tree) de `Tree` une fonction d'affichage, et affichez l'arbre de la première ligne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d.  Écrivez le code qui extrait les groupes nominaux de toutes les phrases (en anglais: Noun Phrases), et qui affiche les 5 les plus fréquents avec leurs nombres d'occurrences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e. Veuillez répéter l'expérience avec un texte plus long (un texte en français du projet Gutenberg) et afficher les 20 groupes nominaux les plus fréquents.  Veuillez indiquer approximativement combien de temps a pris l'analyse syntaxique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Analyse de dépendances\n",
    "\n",
    "Dans cette partie, vous utiliserez le [Stanford Dependency Parser](https://nlp.stanford.edu/software/nndep.html), un analyseur fondé sur un réseau de neurones.\n",
    "\n",
    "* **code Java** : fichier `stanford-corenlp-3.9.2.jar` (8 Mo) fourni sur Cyberlearn (note: on peut le télécharger avec un [package fourni par Stanford](https://nlp.stanford.edu/software/lex-parser.html) ou depuis le [site Maven de Stanford CoreNLP](https://search.maven.org/artifact/edu.stanford.nlp/stanford-corenlp/3.9.2/jar))\n",
    "* **modèle** : fichier `UD_French.gz` (10 Mo) fourni sur Cyberlearn (note: plusieurs modèles sont disponibles sur le site Maven, dont un package pour le français de 272 MB, mais ici vous aurez seulement besoin du modèle UD pour Universal Dependencies)\n",
    "* **données** : les mêmes que pour le labo 2, disponibles dans [l'archive ZIP fournie par l'enseignant](https://drive.switch.ch/index.php/s/5ZNllZOApTWHGwH) (mot de passe = reference).  Ces textes en français proviennent du projet [Universal Dependencies (UD)](https://github.com/UniversalDependencies/UD_French-GSD).  Le fichier `fr-ud-train.conllu3` est destiné à l'entraînement, `fr-ud-dev.conllu3` à la validation, et `fr-ud-test.conllu3` à l'évaluation finale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour effectuer les tâches suivantes, utilisez la [documentation](https://nlp.stanford.edu/nlp/javadoc/javanlp/edu/stanford/nlp/parser/nndep/DependencyParser.html) et regardez surtout le `main()` et les exemples données à la fin.\n",
    "\n",
    "a. Exécuter le parser en Java (avec une commande externe `!java -cp ...` comme au labo 2) en l'appliquant au fichier UD de *test* en français.  Écrivez le résultat détaillé dans un fichier plutôt qu'à l'écran.  Quels sont les deux scores obtenus et que signifient-ils ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veuillez écrire ici la commande pour tester le parser avec le modèle pré-entraîné.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Entraîner l'analyseur de dépendances\n",
    "\n",
    "a. Veuillez entraîner l'analyseur en suivant les indications suivantes:\n",
    "* donnez un nouveau nom au modèle qui sera créé (ne pas écraser l'ancien)\n",
    "* utilisez à la fois `train` et `dev` comme indiqué dans la documentation\n",
    "* évitez un output trop verbeux en le redirigeant vers un fichier `output.txt` (ajoutez `>output.txt 2>&1` à la commande)\n",
    "* plusieurs options indiquées dans la documentation peuvent être utiles\n",
    "  * `-wordCutOff 3` pour traiter seulement les mots apparaissant plus de 3 fois, ce qui évite en particulier le problème des nombres écrits avec un espace (apparaissant 1 fois)\n",
    "  * `-trainingThreads 4` pour utiliser pleinement votre processeur : indiquez le maximum selon votre modèle\n",
    "  * `-maxIter 5000` pour arrêter l'entraînement après 5000 itérations (essayez d'abord beaucoup moins pour vous faire une idée du temps, puis si vous le pouvez, allez plus loin que 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veuillez écrire ici la commande pour entraîner l'analyseur sur le fichier 'train' et créer un nouveau modèle.\n",
    "# Pour ne pas bloquer votre notebook, vous pouvez l'exécuter dans l'invite de commandes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Quels sont les scores (sur les données de test) du système que vous avez entraîné ?  Comment se comparent-ils avec ceux du système par défaut ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veuillez écrire ici la commande pour tester l'analyseur avec le nouveau modèle.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. En traitant le fichier de logs du parser (après l'entraînement), collectez les scores UAS obtenus sur l'ensemble de développement (ou validation).  Affichez sur un graphe l'évolution du score au cours de l'entraînement.  À quelle itération obtenez-vous la valeur maximale de ce score ? Le nombre d'itérations de l'entraînement vous semble-t-il suffisant  ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veuillez écrire ici le code qui extrait les valeurs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Écrivez ici le code affichant les deux courbes.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fin du laboratoire 3\n",
    "\n",
    "Merci de nettoyer votre feuille et de la sauvegarder.  Puis soumettez-la sur Cyberlearn."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "isd",
   "language": "python",
   "name": "isd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
